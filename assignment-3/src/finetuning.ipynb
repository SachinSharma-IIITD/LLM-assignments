{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning LLM\n",
    "Model: **Phi2**\\\n",
    "Datset: **SNLI**\\\n",
    "Technique: **QLORA PEFT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 00:23:11.282578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-02 00:23:11.282636: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-02 00:23:11.283513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-02 00:23:11.289870: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-02 00:23:12.172269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import accelerate\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msachinsharma\u001b[0m (\u001b[33miiitd-sachin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR_PATH = \"../checkpoints/\"\n",
    "DATA_DIR_PATH = \"../data/\"\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR_PATH, exist_ok=True)\n",
    "os.makedirs(DATA_DIR_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../checkpoints/QLoRa-phi2-SNLI'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = \"LLM-A3-PEFT\"\n",
    "base_model_name = \"phi2\"\n",
    "run_name = f'QLoRa-{base_model_name}-SNLI'\n",
    "peft_output_dir = CHECKPOINTS_DIR_PATH + run_name\n",
    "peft_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_and_split(name, train_steps=550, train_len=1000, val_steps=100, val_len=100, test_steps=100, test_len=100):\n",
    "\tdataset = load_dataset(name)\n",
    "\ttrain_dataset = dataset[\"train\"].select(range(0, len(dataset[\"train\"]), train_steps)).take(train_len)\n",
    "\tval_dataset = dataset[\"validation\"].select(range(0, len(dataset[\"validation\"]), val_steps)).take(val_len)\n",
    "\ttest_dataset = dataset[\"test\"].select(range(0, len(dataset[\"test\"]), test_steps)).take(test_len)\n",
    "\n",
    "\t# train_dataset map all -1 labels to 0\n",
    "\ttrain_dataset = train_dataset.map(lambda e: {\"label\": 1 if e[\"label\"] == -1 else e[\"label\"]})\n",
    "\tval_dataset = val_dataset.map(lambda e: {\"label\": 1 if e[\"label\"] == -1 else e[\"label\"]})\n",
    "\ttest_dataset = test_dataset.map(lambda e: {\"label\": 1 if e[\"label\"] == -1 else e[\"label\"]})\n",
    "\t\n",
    "\treturn train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_dataset_and_split(\"stanfordnlp/snli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tokenizer(model_id):\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\tmodel_id,\n",
    "\t\tuse_fast=True,\n",
    "\t)\n",
    "\ttokenizer.pad_token = tokenizer.eos_token\n",
    "\ttokenizer.padding_side = \"left\"\n",
    "\treturn tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = init_tokenizer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "\tprompt_template = \"Premise: {}\\nHypothesis: {}\\nDoes the Hypothesis follows the Premise?\".strip()\n",
    "\tinputs = [prompt_template.format(premise, hypothesis) for premise, hypothesis in zip(batch['premise'], batch['hypothesis'])]\n",
    "\tlabels = batch['label']\n",
    "\ttokenized_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "\ttokenized_inputs[\"labels\"] = labels\n",
    "\treturn tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_dataset(dataset, columns_to_remove=[\"premise\", \"hypothesis\", \"label\"]):\n",
    "\ttokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\ttokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)\n",
    "\ttokenized_dataset.set_format(\"torch\")\n",
    "\treturn tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = get_tokenized_dataset(train_dataset)\n",
    "tokenized_val_dataset = get_tokenized_dataset(val_dataset)\n",
    "tokenized_test_dataset = get_tokenized_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_size(model):\n",
    "\ttotal_params = sum(p.numel() for p in model.parameters())\n",
    "\tdtype = model.parameters().__next__().dtype\n",
    "\ttotal_size_bytes = total_params * dtype.itemsize\n",
    "\ttotal_size_gb = total_size_bytes / (1024 ** 3)\n",
    "\tprint(f\"Model size = {total_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_trainable_size(model):\n",
    "\ttrainable_params = 0\n",
    "\tall_param = 0\n",
    "\tfor _, param in model.named_parameters():\n",
    "\t\tall_param += param.numel()\n",
    "\t\tif param.requires_grad:\n",
    "\t\t\ttrainable_params += param.numel()\n",
    "\t\n",
    "\tdtype = model.parameters().__next__().dtype\n",
    "\ttotal_size_bytes = all_param * dtype.itemsize\n",
    "\ttrainable_size_bytes = trainable_params * dtype.itemsize\n",
    "\ttotal_size_gb = total_size_bytes / (1024 ** 3)\n",
    "\ttrainable_size_gb = trainable_size_bytes / (1024 ** 3)\n",
    "\n",
    "\tprint(\n",
    "\t\tf\"# of total params: {all_param} || # of trainable params: {trainable_params} || trainable %: {(100 * trainable_params / all_param):.2f}%\"\n",
    "\t)\n",
    "\tprint(f\"Total size = {total_size_gb:.2f} GB || Trainable size = {trainable_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_utilization(return_bytes=False):\n",
    "\tnvmlInit()\n",
    "\thandle = nvmlDeviceGetHandleByIndex(0)\n",
    "\tinfo = nvmlDeviceGetMemoryInfo(handle)\n",
    "\tprint(f\"GPU memory occupied: {info.used/(1024**3):.2f} GB.\")\n",
    "\tif return_bytes:\n",
    "\t\treturn info.used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference(model, dataset):\n",
    "\tmodel.eval()\n",
    "\tpredictions, labels = [], []\n",
    "\n",
    "\tfor i in tqdm(range(len(dataset)), desc=\"Inference\", total=len(dataset)):\n",
    "\t\tinput_ids = dataset[i][\"input_ids\"].unsqueeze(0).to(model.device)\n",
    "\t\tattention_mask = dataset[i][\"attention_mask\"].unsqueeze(0).to(model.device)\n",
    "\t\tlabel = dataset[i][\"labels\"].item()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\t\tpredicted_class_id = torch.argmax(outputs.logits, dim=-1).item()\n",
    "\n",
    "\t\tpredictions.append(predicted_class_id)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "\treturn pd.Series(predictions), pd.Series(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(preds, labels):\n",
    "\taccuracy = accuracy_score(labels, preds)\n",
    "\tf1 = f1_score(labels, preds, average='weighted')\n",
    "\treturn {'accuracy': accuracy, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_phi2_model(model_id):\n",
    "\tquantization_config = BitsAndBytesConfig(\n",
    "\t\tload_in_4bit=True,\n",
    "\t\tbnb_4bit_use_double_quant=True,\n",
    "\t\tbnb_4bit_quant_type='nf4',  # Can be 'nf4' or 'fp4'\n",
    "\t\tbnb_4bit_compute_dtype=torch.float16\n",
    "\t)\n",
    "\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\tmodel_id,\n",
    "\t\tnum_labels=3,\n",
    "\t\ttorch_dtype=torch.float16,\n",
    "\t\tlow_cpu_mem_usage=True,\n",
    "\t\ttrust_remote_code=True,\n",
    "\t\tquantization_config=quantization_config,\n",
    "\t\tdevice_map='auto',\n",
    "\t\t# device_map={\"\": 0}\n",
    "\t)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 0.36 GB.\n"
     ]
    }
   ],
   "source": [
    "get_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca80774feb49447f9b5890d05292fd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PhiForSequenceClassification were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = init_phi2_model(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total params: 1390277120 || # of trainable params: 131248640 || trainable %: 9.44%\n",
      "Total size = 2.59 GB || Trainable size = 0.24 GB\n"
     ]
    }
   ],
   "source": [
    "display_trainable_size(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21921d0f3b1e4ae4a37a9b864c01d2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    }
   ],
   "source": [
    "base_model_preds, labels = get_inference(base_model, tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    97\n",
       "0     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.39, 'f1': 0.2494326725905673}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_metrics = evaluate_prediction(base_model_preds, labels)\n",
    "base_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lora_model(base_model):\n",
    "\tlora_config = LoraConfig(\n",
    "\t\ttask_type=TaskType.SEQ_CLS,\n",
    "\t\tr=32,\n",
    "\t\tlora_alpha=64,\n",
    "\t\ttarget_modules='all-linear',\n",
    "\t\tlora_dropout=0.05,\n",
    "\t)\n",
    "\t\n",
    "\tbase_model = prepare_model_for_kbit_training(base_model)\n",
    "\tbase_model.gradient_checkpointing_enable()\n",
    "\n",
    "\tlora_model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "\tfor name, param in lora_model.named_parameters():\n",
    "\t\tif 'lora' not in name:\n",
    "\t\t\tparam.requires_grad = False\n",
    "\n",
    "\treturn lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2.39 GB.\n"
     ]
    }
   ],
   "source": [
    "gpu_util_before_ft = get_gpu_utilization(return_bytes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_lora_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total params: 1437470720 || # of trainable params: 47185920 || trainable %: 3.28%\n",
      "Total size = 5.35 GB || Trainable size = 0.18 GB\n"
     ]
    }
   ],
   "source": [
    "display_trainable_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): PhiForSequenceClassification(\n",
       "      (model): PhiModel(\n",
       "        (embed_tokens): Embedding(51200, 2560)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x PhiDecoderLayer(\n",
       "            (self_attn): PhiSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dense): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): PhiRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): PhiMLP(\n",
       "              (activation_fn): NewGELUActivation()\n",
       "              (fc1): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=10240, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (fc2): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=10240, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2560, out_features=3, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2560, out_features=3, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_training_args = TrainingArguments(\n",
    "\tnum_train_epochs=5,\n",
    "\toutput_dir = peft_output_dir,\n",
    "\tper_device_train_batch_size=32,\n",
    "\tper_device_eval_batch_size=32,  \n",
    "\tlearning_rate=0.0001,\n",
    "\tweight_decay=0.001,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "\tlogging_dir=CHECKPOINTS_DIR_PATH + \"logs/\",\n",
    "\tlogging_strategy=\"epoch\",\n",
    "\tsave_strategy=\"epoch\",\n",
    "\teval_strategy=\"epoch\",\n",
    "\tfp16=True,\n",
    "\toverwrite_output_dir = 'True',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsl/gpu_env_pip/lib64/python3.10/site-packages/accelerate/accelerator.py:469: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "\tmodel=model,\n",
    "\ttrain_dataset=tokenized_train_dataset,\n",
    "\teval_dataset=tokenized_val_dataset,\n",
    "\targs=peft_training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nsl/llm/assignment-3/src/wandb/run-20241102_002340-j930ab8l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iiitd-sachin/huggingface/runs/j930ab8l' target=\"_blank\">../checkpoints/QLoRa-phi2-SNLI</a></strong> to <a href='https://wandb.ai/iiitd-sachin/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iiitd-sachin/huggingface' target=\"_blank\">https://wandb.ai/iiitd-sachin/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iiitd-sachin/huggingface/runs/j930ab8l' target=\"_blank\">https://wandb.ai/iiitd-sachin/huggingface/runs/j930ab8l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsl/gpu_env_pip/lib64/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 11:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.049400</td>\n",
       "      <td>0.591291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>0.373745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>0.502573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.495568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.545783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsl/gpu_env_pip/lib64/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/nsl/gpu_env_pip/lib64/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/nsl/gpu_env_pip/lib64/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/nsl/gpu_env_pip/lib64/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 722.81 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "peft_trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(f\"Training time: {time_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3d53f379d6450f879b86f866f723db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_model_preds, labels = get_inference(model, tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.88, 'f1': 0.878125}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_prediction(peft_model_preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 8.83 GB.\n"
     ]
    }
   ],
   "source": [
    "gpu_util_after_ft = get_gpu_utilization(return_bytes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory consumed during fine-tuning: 6.43 GB\n"
     ]
    }
   ],
   "source": [
    "gpu_util_diff = (gpu_util_after_ft - gpu_util_before_ft) / (1024 ** 3)\n",
    "print(f\"GPU memory consumed during fine-tuning: {gpu_util_diff:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base_model, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = init_tokenizer(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3970b2fc973421a8fd6b8659534ca9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PhiForSequenceClassification were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = init_phi2_model(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total params: 1390277120 || # of trainable params: 131248640 || trainable %: 9.44%\n",
      "Total size = 2.59 GB || Trainable size = 0.24 GB\n"
     ]
    }
   ],
   "source": [
    "display_trainable_size(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2925dfe4ab34c269b7915a68eec0fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Test Metrics:\n",
      "Accuracy: 0.33 || F1: 0.20\n"
     ]
    }
   ],
   "source": [
    "base_model_preds, labels = get_inference(base_model, tokenized_test_dataset)\n",
    "base_model_metrics = evaluate_prediction(base_model_preds, labels)\n",
    "print(\"Base Model Test Metrics:\")\n",
    "print(f'Accuracy: {base_model_metrics[\"accuracy\"]:.2f} || F1: {base_model_metrics[\"f1\"]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failure Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693511ef7cfb46a7b2761bb92737d5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_case_examples = test_dataset.select(range(0, 5))\n",
    "tokenized_test_case_examples = get_tokenized_dataset(test_case_examples)\n",
    "base_model_test_case_preds, labels = get_inference(base_model, tokenized_test_case_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This church choir sings to the masses as they ...</td>\n",
       "      <td>The church has cracks in the ceiling.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two men climbing on a wooden scaffold.</td>\n",
       "      <td>Two sad men climbing on a wooden scaffold.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man in a black shirt, in a commercial kitche...</td>\n",
       "      <td>A man in a black shirt, in a commercial kitche...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a woman in a black shirt looking at a bicycle.</td>\n",
       "      <td>A woman dressed in black shops for a bicycle.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  This church choir sings to the masses as they ...   \n",
       "2             Two men climbing on a wooden scaffold.   \n",
       "3  A man in a black shirt, in a commercial kitche...   \n",
       "4     a woman in a black shirt looking at a bicycle.   \n",
       "\n",
       "                                          hypothesis  label  predicted_label  \n",
       "0              The church has cracks in the ceiling.      1                0  \n",
       "2         Two sad men climbing on a wooden scaffold.      1                0  \n",
       "3  A man in a black shirt, in a commercial kitche...      1                0  \n",
       "4      A woman dressed in black shops for a bicycle.      1                0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_test_case_failures = test_case_examples.to_pandas()[base_model_test_case_preds != labels]\n",
    "base_model_test_case_failures['predicted_label'] = base_model_test_case_preds.iloc[base_model_test_case_failures.index]\n",
    "base_model_test_case_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_test_case_failures.to_csv(DATA_DIR_PATH + \"base_model_test_case_failures.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_checkpoint(output_dir):\n",
    "\tcheckpoint_files = os.listdir(output_dir)\n",
    "\tlatest_checkpoint = max(checkpoint_files, key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "\treturn latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint-160'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint = find_latest_checkpoint(peft_output_dir)\n",
    "latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModelForSequenceClassification.from_pretrained(base_model, peft_output_dir + '/' + latest_checkpoint, is_trainable=False, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total params: 1437470720 || # of trainable params: 7680 || trainable %: 0.00%\n",
      "Total size = 2.68 GB || Trainable size = 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "display_trainable_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2b05be6e6f4ddc90c19700bb9fe1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Finetuned Model Test Metrics:\n",
      "Accuracy: 0.88 || F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "model_preds, labels = get_inference(model, tokenized_test_dataset)\n",
    "model_metrics = evaluate_prediction(model_preds, labels)\n",
    "print(\"PEFT Finetuned Model Test Metrics:\")\n",
    "print(f'Accuracy: {model_metrics[\"accuracy\"]:.2f} || F1: {model_metrics[\"f1\"]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b30341346e9406b9535fd3b4c4bb92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'f1': 0.8857142857142858}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_case_preds, labels = get_inference(model, tokenized_test_case_examples)\n",
    "evaluate_prediction(model_test_case_preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This church choir sings to the masses as they ...</td>\n",
       "      <td>The church has cracks in the ceiling.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  This church choir sings to the masses as they ...   \n",
       "\n",
       "                              hypothesis  label  predicted_label  \n",
       "0  The church has cracks in the ceiling.      1                2  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_case_failures = test_case_examples.to_pandas()[model_test_case_preds != labels]\n",
    "model_test_case_failures['predicted_label'] = model_test_case_preds.iloc[model_test_case_failures.index]\n",
    "model_test_case_misses = model_test_case_failures[model_test_case_failures['premise'].isin(base_model_test_case_failures['premise'])]\n",
    "model_test_case_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_case_misses.to_csv(DATA_DIR_PATH + \"model_test_case_misses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two men climbing on a wooden scaffold.</td>\n",
       "      <td>Two sad men climbing on a wooden scaffold.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man in a black shirt, in a commercial kitche...</td>\n",
       "      <td>A man in a black shirt, in a commercial kitche...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a woman in a black shirt looking at a bicycle.</td>\n",
       "      <td>A woman dressed in black shops for a bicycle.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "2             Two men climbing on a wooden scaffold.   \n",
       "3  A man in a black shirt, in a commercial kitche...   \n",
       "4     a woman in a black shirt looking at a bicycle.   \n",
       "\n",
       "                                          hypothesis  label  predicted_label  \n",
       "2         Two sad men climbing on a wooden scaffold.      1                1  \n",
       "3  A man in a black shirt, in a commercial kitche...      1                1  \n",
       "4      A woman dressed in black shops for a bicycle.      1                1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_case_success = test_case_examples.to_pandas()[model_test_case_preds == labels]\n",
    "model_test_case_success['predicted_label'] = model_test_case_preds.iloc[model_test_case_success.index]\n",
    "model_test_case_improvs = model_test_case_success[model_test_case_success['premise'].isin(base_model_test_case_failures['premise'])]\n",
    "model_test_case_improvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_case_improvs.to_csv(DATA_DIR_PATH + \"model_test_case_improvs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
